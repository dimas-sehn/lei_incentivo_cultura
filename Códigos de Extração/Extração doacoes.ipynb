{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"y2McpQWNKUDi","executionInfo":{"status":"error","timestamp":1691376859625,"user_tz":180,"elapsed":7,"user":{"displayName":"Sem Início Sem Fim Produtora Cultural","userId":"10182748856344207795"}},"outputId":"1b29d361-fdb3-4739-8438-f449ffc34671"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-32c835f6d6ee>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/doacoes.csv'"]}],"source":["import requests\n","from google.cloud import storage\n","import csv\n","import json\n","import os\n","import re\n","import chardet\n","\n","def strip_tags(html_text):\n","    clean_text = re.sub(r\"<[^>]*>\", \"\", html_text)\n","    return clean_text\n","\n","def extract_data_from_link(link):\n","    try:\n","        response = requests.get(link)\n","        response.raise_for_status()  # Verificar se a solicitação foi bem-sucedida\n","\n","        # Codificações a serem tentadas em ordem de probabilidade\n","        encodings_to_try = [\"utf-8\", \"iso-8859-1\", \"windows-1252\"]\n","\n","        for encoding in encodings_to_try:\n","            try:\n","                data = json.loads(response.content.decode(encoding))[\"_embedded\"][\"doacoes\"]\n","                break\n","            except UnicodeDecodeError:\n","                continue\n","\n","        # Limpar o conteúdo dos objetos\n","        for item in data:\n","            if \"campo_de_texto\" in item:\n","                item[\"campo_de_texto\"] = strip_tags(item[\"campo_de_texto\"])\n","\n","        return data\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error during API request for link {link}: {e}\")\n","        return []\n","\n","def upload_to_google_cloud_storage(bucket_name, data, filename, key_path):\n","    try:\n","        client = storage.Client.from_service_account_json(key_path)\n","        bucket = client.bucket(bucket_name)\n","        blob = bucket.blob(filename)\n","\n","        # Preparar os dados como linhas separadas no arquivo JSON\n","        data_json_lines = \"\\n\".join(json.dumps(obj, ensure_ascii=False) for obj in data)\n","\n","        # Fazer o upload dos dados no formato UTF-8\n","        blob.upload_from_string(data_json_lines.encode(\"utf-8\"), content_type=\"application/json; charset=utf-8\")\n","        print(f\"Data from {len(data)} links uploaded to gs://{bucket_name}/{filename}\")\n","        return True\n","    except Exception as e:\n","        print(f\"Error during data upload: {e}\")\n","        return False\n","\n","if __name__ == \"__main__\":\n","    input_csv_path = \"/content/doacoes.csv\"  # Substitua pelo caminho para o CSV contendo os links\n","    bucket_name = \"salic_dados\"  # Substitua pelo nome do seu bucket\n","    filename = \"doacoes.json\"  # Nome do arquivo no bucket\n","    key_path = \"/content/salic-web-37918cc40c59.json\"  # Caminho para a chave de acesso JSON\n","\n","    all_data = []\n","    with open(input_csv_path, \"r\", newline=\"\") as csvfile:\n","        reader = csv.reader(csvfile)\n","        for row in reader:\n","            link = row[0]\n","            data = extract_data_from_link(link)\n","            all_data.extend(data)\n","\n","    if all_data:\n","        # Enviar todos os dados para o Google Cloud Storage em um único arquivo JSON\n","        if upload_to_google_cloud_storage(bucket_name, all_data, filename, key_path):\n","            print(\"Data uploaded successfully.\")\n","        else:\n","            print(\"Data upload failed. Check the error messages for more information.\")\n","\n","    print(\"All data has been extracted and uploaded.\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPN4rLKZ1jtt6G0pFaoPN0p"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}